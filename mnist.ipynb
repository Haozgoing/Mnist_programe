{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision.datasets\nimport matplotlib.pyplot as plt\nimport torchvision.transforms\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nimport cv2\nfrom torch.utils.tensorboard import SummaryWriter\n\n# 使用随机化种子使神经网络的初始化每次都相同\ntorch.manual_seed(1)\n\n# 超参数\nEPOCH = 20  # 训练整批数据的次数\nDOWNLOAD_MNIST = True  # 表示还没有下载数据集，如果数据集下载好了就写False\nBATCH_SIZE = 64\nLR = 0.001  # 学习率\n\ntrain_data = torchvision.datasets.MNIST(root='dataset', train=True,\n                                        transform=torchvision.transforms.ToTensor(),\n                                        download=True)\n\ntest_data = torchvision.datasets.MNIST(root='dataset', train=False,\n                                       transform=torchvision.transforms.ToTensor(),\n                                       download=True)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-10T10:32:50.640793Z","iopub.execute_input":"2023-08-10T10:32:50.641177Z","iopub.status.idle":"2023-08-10T10:33:04.551099Z","shell.execute_reply.started":"2023-08-10T10:32:50.641146Z","shell.execute_reply":"2023-08-10T10:33:04.549844Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 103486266.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 63621687.93it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"\n100%|██████████| 1648877/1648877 [00:00<00:00, 25993533.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 1924101.48it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# 批训练 50个samples， 1个channel， 28x28 (50, 1, 28, 28)\n# Torch中的DataLoader是用来包装的数据工具，它能够帮我们有效迭代数据，这样可以进行批训练\n# shuffle为true一般打乱数据\ntrain_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\ntest_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n\n# 定义一个转换，将张量转换为PIL图像\nto_pil = torchvision.transforms.ToPILImage()\n\n# 查看64个图像拼凑的一张图片\nimgs, labels = next(iter(train_dataloader))\nimg = torchvision.utils.make_grid(imgs) # 把64张图片拼接为一张图片\n# pytorch网络输入图像的格式为（C,H,W），而numpy中图像的shaoe为（H，W，C）故需要变换通道才能有效输出\nimg = img.numpy().transpose(1, 2, 0)\nstd = [0.5, 0.5, 0.5]\nmean = [0.5, 0.5, 0.5]\nimg = img * std + mean\n# print(labels)\n# plt.imshow(img)\n# plt.show()\n\n# writer = SummaryWriter('logs_mnist')\n\nfor data in train_dataloader:\n    imgs, targets = data\n    # print(imgs[0])\n    # print(imgs.shape)\n    # print(targets[0])\n    # # 取出第一张图片\n    # pil_image = imgs[0]\n    # # 将张量转换为PIL图像\n    # pil_image = to_pil(pil_image)\n    # pil_image.show()\n    break\n\n\n# writer.close()\n\n# 进行测试\n# 为节约时间，测试时只测试前2000个\ntest_x = torch.unsqueeze(test_data.train_data, dim=1).type(torch.FloatTensor)[:2000] / 255\ntest_x = test_x.to(device)  # 将测试数据移至GPU上\n# torch.unsqueeze(a) 是用来对数据维度进行扩充，这样shape就从(2000,28,28)->(2000,1,28,28)\n# 图像的pixel本来是0到255之间，除以255对图像进行归一化使取值范围在(0,1)\ntest_y = test_data.test_labels[:2000]\n\n\n\n\n# 用class类来建立CNN模型\n# CNN流程：卷积(Conv2d)-> 激励函数(ReLU)->池化(MaxPooling)->\n#        卷积(Conv2d)-> 激励函数(ReLU)->池化(MaxPooling)->\n#        展平多维的卷积成的特征图->接入全连接层(Linear)->输出\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # 建立第一个卷积(Conv2d)->激励函数(ReLu)->池化(MaxPooling)\n        self.conv1 = nn.Sequential(\n            # 第一个卷积cond2d\n            nn.Conv2d( # 输入图像太小(1,28,28)\n                in_channels=1, # 输入图片是灰度图像只有一个通道\n                out_channels=16,\n                kernel_size=5, # 卷积核大小\n                stride=1,\n                padding=2 # 想要cond2d输出的图片长宽不变就要进行补0操作 padding = (kernel_size-1)/2\n            ), # 输出图像大小(16, 28, 28)\n            # 激活函数\n            nn.ReLU(),\n            # 池化 下采样\n            nn.MaxPool2d(kernel_size=2) # 在2x2空间下采样\n            # 输出图像大小(16,14,14)\n        )\n\n        # 建立第二个卷积(Conv2d)->激励函数(ReLu)->池化(MaxPooling)\n        self.conv2 = nn.Sequential(\n            # 输入图像大小(16,14,14)\n            nn.Conv2d(\n                in_channels=16,\n                out_channels=32,\n                kernel_size=5,\n                stride=1,\n                padding=2\n            ), # 输出图像大小(32, 14, 14)\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2)\n            # 输出图像大小(32,7,7)\n        )\n\n        # 建立全卷积连接层\n        self.out = nn.Linear(32 * 7 * 7, 10) # 输出是十个类\n\n    # 下面定义x的传播路线\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        # 把每一个批次的每一个输入都拉成一个维度，即(batch_size,32*7*7)\n        # 因为pytorch里特征的形式是[bs,channel,h,w]，所以x.size(0)就是batchsize\n        x = x.view(x.size(0), -1)  # view就是把x弄成batchsize行个tensor\n        output = self.out(x)\n        return output\n\n","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:34:40.142661Z","iopub.execute_input":"2023-08-10T10:34:40.143174Z","iopub.status.idle":"2023-08-10T10:34:40.245135Z","shell.execute_reply.started":"2023-08-10T10:34:40.143132Z","shell.execute_reply":"2023-08-10T10:34:40.243981Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device =torch.device('cuda:0')\ncnn = CNN().to(device)\n# print(cnn)\n\n# 训练\n# 把x和y 都放入Variable中，然后放入cnn中计算output，最后再计算误差\n\n# 优化器选择Adam\noptimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n# 损失函数\nloss_func = nn.CrossEntropyLoss().to(device) # 目标标签是one-hotted\n\n# 开始训练\nfor epoch in range(EPOCH):\n    for step, (b_x, b_y) in enumerate(train_dataloader):\n        b_x, b_y = b_x.to(device), b_y.to(device)  # 将数据移至GPU\n        output = cnn(b_x) # 先将数据放到cnn中计算output\n        loss = loss_func(output, b_y) # 输出和真实标签的loss，二者位置不可以颠倒\n        optimizer.zero_grad() # 清楚之前学到的梯度的参数\n        loss.backward() # 反向传播，计算梯度\n        optimizer.step() # 应用梯度\n\n        if step % 64 ==0:\n            test_output = cnn(test_x)\n            # print(test_output)\n            # pred_y = torch.max(test_output, 1)[1].data.numpy()\n            pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n            accuracy = float((pred_y == test_y.data.numpy()).astype(int).sum()) / float(test_y.size(0))\n            print('Epoch', epoch+1, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.2f' % accuracy)\n\n\n# 保存模型\ntorch.save(cnn.state_dict(), 'cnn.pkl')","metadata":{"execution":{"iopub.status.busy":"2023-08-10T10:35:24.654643Z","iopub.execute_input":"2023-08-10T10:35:24.655073Z","iopub.status.idle":"2023-08-10T10:38:33.202829Z","shell.execute_reply.started":"2023-08-10T10:35:24.655041Z","shell.execute_reply":"2023-08-10T10:38:33.201716Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Epoch 1 | train loss: 2.3025 | test accuracy: 0.26\nEpoch 1 | train loss: 0.4486 | test accuracy: 0.84\nEpoch 1 | train loss: 0.3866 | test accuracy: 0.89\nEpoch 1 | train loss: 0.1930 | test accuracy: 0.92\nEpoch 1 | train loss: 0.0952 | test accuracy: 0.95\nEpoch 1 | train loss: 0.1314 | test accuracy: 0.95\nEpoch 1 | train loss: 0.1118 | test accuracy: 0.95\nEpoch 1 | train loss: 0.1051 | test accuracy: 0.96\nEpoch 1 | train loss: 0.1389 | test accuracy: 0.96\nEpoch 1 | train loss: 0.0867 | test accuracy: 0.97\nEpoch 1 | train loss: 0.2021 | test accuracy: 0.97\nEpoch 1 | train loss: 0.0817 | test accuracy: 0.97\nEpoch 1 | train loss: 0.0732 | test accuracy: 0.97\nEpoch 1 | train loss: 0.0245 | test accuracy: 0.98\nEpoch 1 | train loss: 0.0284 | test accuracy: 0.97\nEpoch 2 | train loss: 0.0549 | test accuracy: 0.97\nEpoch 2 | train loss: 0.0210 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0882 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0247 | test accuracy: 0.97\nEpoch 2 | train loss: 0.0737 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0333 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0956 | test accuracy: 0.98\nEpoch 2 | train loss: 0.1695 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0750 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0130 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0307 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0452 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0290 | test accuracy: 0.98\nEpoch 2 | train loss: 0.0878 | test accuracy: 0.97\nEpoch 2 | train loss: 0.1792 | test accuracy: 0.98\nEpoch 3 | train loss: 0.1326 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0376 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0138 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0527 | test accuracy: 0.99\nEpoch 3 | train loss: 0.0311 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0116 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0338 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0219 | test accuracy: 0.99\nEpoch 3 | train loss: 0.0141 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0316 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0629 | test accuracy: 0.98\nEpoch 3 | train loss: 0.1166 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0103 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0501 | test accuracy: 0.98\nEpoch 3 | train loss: 0.0367 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0392 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0101 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0055 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0903 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0070 | test accuracy: 0.99\nEpoch 4 | train loss: 0.0116 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0439 | test accuracy: 0.99\nEpoch 4 | train loss: 0.0360 | test accuracy: 0.99\nEpoch 4 | train loss: 0.0165 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0008 | test accuracy: 0.99\nEpoch 4 | train loss: 0.0238 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0251 | test accuracy: 0.99\nEpoch 4 | train loss: 0.0336 | test accuracy: 0.98\nEpoch 4 | train loss: 0.1118 | test accuracy: 0.98\nEpoch 4 | train loss: 0.0042 | test accuracy: 0.98\nEpoch 5 | train loss: 0.0200 | test accuracy: 0.98\nEpoch 5 | train loss: 0.0220 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0226 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0013 | test accuracy: 0.98\nEpoch 5 | train loss: 0.0948 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0026 | test accuracy: 0.98\nEpoch 5 | train loss: 0.0600 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0031 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0160 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0073 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0625 | test accuracy: 0.98\nEpoch 5 | train loss: 0.0195 | test accuracy: 0.98\nEpoch 5 | train loss: 0.0336 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0049 | test accuracy: 0.99\nEpoch 5 | train loss: 0.0148 | test accuracy: 0.98\nEpoch 6 | train loss: 0.0462 | test accuracy: 0.98\nEpoch 6 | train loss: 0.0093 | test accuracy: 0.98\nEpoch 6 | train loss: 0.0433 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0256 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0223 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0076 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0012 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0110 | test accuracy: 0.98\nEpoch 6 | train loss: 0.0026 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0311 | test accuracy: 0.98\nEpoch 6 | train loss: 0.0041 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0015 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0150 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0017 | test accuracy: 0.99\nEpoch 6 | train loss: 0.0141 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0102 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0177 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0124 | test accuracy: 0.98\nEpoch 7 | train loss: 0.0053 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0164 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0124 | test accuracy: 0.98\nEpoch 7 | train loss: 0.0281 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0084 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0061 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0041 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0077 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0267 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0225 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0244 | test accuracy: 0.99\nEpoch 7 | train loss: 0.0176 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0150 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0091 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0011 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0131 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0249 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0918 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0067 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0033 | test accuracy: 0.98\nEpoch 8 | train loss: 0.0544 | test accuracy: 0.98\nEpoch 8 | train loss: 0.0570 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0100 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0011 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0480 | test accuracy: 0.99\nEpoch 8 | train loss: 0.0218 | test accuracy: 0.98\nEpoch 8 | train loss: 0.0178 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0106 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0062 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0045 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0047 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0015 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0150 | test accuracy: 0.98\nEpoch 9 | train loss: 0.0016 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0009 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0027 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0021 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0077 | test accuracy: 0.99\nEpoch 9 | train loss: 0.0309 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0071 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0093 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0156 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0064 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0208 | test accuracy: 0.98\nEpoch 10 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0483 | test accuracy: 0.98\nEpoch 10 | train loss: 0.0067 | test accuracy: 0.98\nEpoch 10 | train loss: 0.0043 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0250 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0187 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0014 | test accuracy: 0.99\nEpoch 10 | train loss: 0.0050 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0005 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0078 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0016 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0120 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0078 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0229 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0072 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0014 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0021 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0016 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0083 | test accuracy: 0.99\nEpoch 11 | train loss: 0.0018 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0061 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0007 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0069 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0757 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0011 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0031 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0181 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0106 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0464 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0010 | test accuracy: 0.99\nEpoch 12 | train loss: 0.0056 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0032 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0019 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0759 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0085 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0030 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0138 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0039 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0119 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0045 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0236 | test accuracy: 0.98\nEpoch 13 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 13 | train loss: 0.0350 | test accuracy: 0.98\nEpoch 14 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0008 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0219 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0050 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0131 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0022 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0021 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0090 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0423 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0017 | test accuracy: 0.99\nEpoch 14 | train loss: 0.0042 | test accuracy: 0.98\nEpoch 15 | train loss: 0.0011 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0005 | test accuracy: 0.98\nEpoch 15 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0025 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0018 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0005 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0008 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0334 | test accuracy: 0.98\nEpoch 15 | train loss: 0.0067 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0011 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0035 | test accuracy: 0.99\nEpoch 15 | train loss: 0.0186 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0003 | test accuracy: 0.98\nEpoch 16 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0005 | test accuracy: 0.98\nEpoch 16 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0006 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0053 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0242 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0034 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0349 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0035 | test accuracy: 0.99\nEpoch 16 | train loss: 0.0038 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0009 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0014 | test accuracy: 0.98\nEpoch 17 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0020 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0017 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0049 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0000 | test accuracy: 0.98\nEpoch 17 | train loss: 0.0051 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0031 | test accuracy: 0.99\nEpoch 17 | train loss: 0.0002 | test accuracy: 0.98\nEpoch 18 | train loss: 0.0005 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0073 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0024 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0928 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0076 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0008 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0185 | test accuracy: 0.99\nEpoch 18 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0002 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0008 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0337 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 19 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0004 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0004 | test accuracy: 0.98\nEpoch 20 | train loss: 0.0004 | test accuracy: 0.98\nEpoch 20 | train loss: 0.0254 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0001 | test accuracy: 0.98\nEpoch 20 | train loss: 0.0179 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0075 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0003 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0013 | test accuracy: 0.98\nEpoch 20 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0001 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0000 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0061 | test accuracy: 0.99\nEpoch 20 | train loss: 0.0031 | test accuracy: 0.99\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}